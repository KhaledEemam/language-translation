{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrQszFWtdQ69"
      },
      "source": [
        "# Connecting to Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHF52m0LRwng",
        "outputId": "a168264d-d947-4ef5-da4f-836e017d16a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ANMH9mJxcid"
      },
      "source": [
        "# Importing Packages & dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TWnKQStxl7_"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import TextVectorization , Embedding , Dense , TimeDistributed , LSTM , GRU , RNN , Bidirectional\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh-OLRfadXEA"
      },
      "source": [
        "# Importing Data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpQUY2zYR78Z"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/Datasets/language_translation/small_vocab_en\") as f :\n",
        "  data_eng = f.read() \n",
        "\n",
        "with open(\"/content/drive/MyDrive/Datasets/language_translation/small_vocab_fr\") as f :\n",
        "  data_fr = f.read() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZQsAi95tSk6"
      },
      "source": [
        "# Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGR0JFwZuRZz"
      },
      "outputs": [],
      "source": [
        "def print_stats(text,language) :\n",
        "   print(\"Number of lines in the {} dataset = {}\".format(language,len(text.split(\"\\n\"))))\n",
        "   print(\"Number of words in the {} dataset = {}\".format(language,len(text.split())))\n",
        "   print(\"Number of unique words in the {} dataset = {}\".format(language,len(set(text.split()))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5u65eXju6Kt",
        "outputId": "927020b7-4514-44aa-a111-80f18d823b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of lines in the english dataset = 137861\n",
            "Number of words in the english dataset = 1823250\n",
            "Number of unique words in the english dataset = 227\n",
            "Number of lines in the french dataset = 137861\n",
            "Number of words in the french dataset = 1961295\n",
            "Number of unique words in the french dataset = 355\n"
          ]
        }
      ],
      "source": [
        "print_stats(data_eng,\"english\")\n",
        "print_stats(data_fr,\"french\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB-QuzS1s8GK"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtCafquTBNpP"
      },
      "source": [
        "## 1-Cleaning texts\n",
        "\n",
        "\n",
        "*   Lowering the text\n",
        "*   Punctuation Removal\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0Stg3LkBEn6"
      },
      "outputs": [],
      "source": [
        "def clean_text(text) :\n",
        "  text = text.lower()\n",
        "  text = text.translate(str.maketrans('','',string.punctuation))\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUOskDVxqj4z"
      },
      "outputs": [],
      "source": [
        "data_eng = clean_text(data_eng).split(\"\\n\")\n",
        "data_fr = clean_text(data_fr).split(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvLwtr5AtAUu"
      },
      "source": [
        "## 2-Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUay_pLKs7fk"
      },
      "outputs": [],
      "source": [
        "def tokenize(text) : \n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(text)\n",
        "  sequences = tokenizer.texts_to_sequences(text)\n",
        "  return sequences , tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRu6Uf0fMdjX"
      },
      "source": [
        "## 3-Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax5cERKnK8Xh"
      },
      "outputs": [],
      "source": [
        "def pad(sequence , max_length = None ) :\n",
        "  return pad_sequences(sequence , maxlen = max_length , padding = \"post\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQjWV1iCl6gv"
      },
      "source": [
        "# Preprocess Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glYMm1yL1FfQ"
      },
      "source": [
        "## 1-Using the predefined functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKxeTUlYMToD"
      },
      "outputs": [],
      "source": [
        "def preprocess(x, y ) :\n",
        "  preprocess_x , x_tk = tokenize(x)\n",
        "  preprocess_y , y_tk = tokenize(y)\n",
        "  preprocess_x = pad(preprocess_x)\n",
        "  preprocess_y = pad(preprocess_y)\n",
        "  preprocess_y = preprocess_y.reshape(*preprocess_y.shape,1)\n",
        "  return preprocess_x , preprocess_y , x_tk , y_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx39LOjmnnZ6"
      },
      "outputs": [],
      "source": [
        "preproc_english_sentences, preproc_french_sentences , english_tokenizer, french_tokenizer = preprocess(data_eng,data_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XirHHBuZupQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3307e3bf-ddfd-4ce8-df5d-beea5b30efcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 15\n",
            "Max French sentence length: 21\n",
            "English vocabulary size: 199\n",
            "French vocabulary size: 344\n"
          ]
        }
      ],
      "source": [
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab = english_tokenizer.word_index\n",
        "french_vocab = french_tokenizer.word_index\n",
        "english_vocab_size = len(english_vocab)\n",
        "french_vocab_size = len(french_vocab)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAqg13-wzPfI"
      },
      "source": [
        "## 2- Using tokenization through \"TextVectorization\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-xzVI8PvTp_"
      },
      "outputs": [],
      "source": [
        "def text_vectorization(text_data,max_length) : \n",
        "  vectorize_layer = tf.keras.layers.TextVectorization(output_mode='int', output_sequence_length=max_length)\n",
        "  vectorize_layer.adapt(text_data)\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(vectorize_layer)\n",
        "  return model.predict(text_data),(vectorize_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUNOonL8yNcQ"
      },
      "outputs": [],
      "source": [
        "def get_max_padding_length(text) :\n",
        "  max = 0\n",
        "  for item in text :\n",
        "    length = len(item.split())\n",
        "    if max < length :\n",
        "      max = length\n",
        "  return max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi_g8g-RyYcR"
      },
      "outputs": [],
      "source": [
        "max_english_sequence_length = get_max_padding_length(data_eng)\n",
        "max_french_sequence_length = get_max_padding_length(data_fr)\n",
        "preproc_english_sentences_2 , english_vocab_2 = text_vectorization(data_eng,max_english_sequence_length)\n",
        "preproc_french_sentences_2 , french_vocab_2 = text_vectorization(data_fr,max_french_sequence_length)\n",
        "english_vocab_size = len(english_vocab_2)\n",
        "french_vocab_size = len(french_vocab_2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preproc_french_sentences_2 = preproc_french_sentences_2.reshape(*preproc_french_sentences_2.shape,)"
      ],
      "metadata": {
        "id": "N3s9wYES-j6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBTDUOZuye0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1980c65e-874e-4534-cb88-eb367d43d689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 15\n",
            "Max French sentence length: 21\n",
            "English vocabulary size: 201\n",
            "French vocabulary size: 346\n"
          ]
        }
      ],
      "source": [
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preproc_english_sentences_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMHImtI2a6dw",
        "outputId": "5859d109-5d13-4d43-dc7b-0e41ccd5d36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137861, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preproc_french_sentences_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAdlNWE5a-zH",
        "outputId": "8be94a47-7275-489c-a541-8e7ad7931fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137861, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Models"
      ],
      "metadata": {
        "id": "xHfh2pIu-uSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ids Back to Text"
      ],
      "metadata": {
        "id": "95QUq7UmQRky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id : word for word , id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = \"<PAD>\"\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits,1)])"
      ],
      "metadata": {
        "id": "-qg1qEMpQQ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: RNN"
      ],
      "metadata": {
        "id": "X7u5gPYI-zI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_model(input_shape, french_vocab_size):\n",
        "\n",
        "  # HyperParameter \n",
        "  learning_rate = .005\n",
        "\n",
        "  # Build the layers \n",
        "\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(GRU(256,return_sequences=True,input_shape=input_shape[1:]))\n",
        "  model.add(TimeDistributed(Dense(1024,activation = \"relu\")))\n",
        "  model.add(keras.layers.Dropout(.5))\n",
        "  model.add(TimeDistributed(Dense(french_vocab_size , activation = \"softmax\")))\n",
        "  model.compile(loss = sparse_categorical_crossentropy , metrics = [\"accuracy\"] , optimizer = keras.optimizers.Adam(learning_rate))\n",
        "  return model\n",
        "\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences , max_french_sequence_length )\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
        "\n",
        "# Training simple model \n",
        "simple_rnn_model  = simple_model(tmp_x.shape, french_vocab_size)\n",
        "\n",
        "print(simple_rnn_model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19tcdkwy-eNn",
        "outputId": "84484f43-fe21-4b2c-f24e-05a748b0cfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 21, 256)           198912    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 21, 1024)         263168    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 21, 346)          354650    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 816,730\n",
            "Trainable params: 816,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
        "simple_rnn_model.save(\"sinple_rnn_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQUamYWC1ERB",
        "outputId": "e7d3b646-75a1-4399-fe7a-ac68bb5cb9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "108/108 [==============================] - 13s 55ms/step - loss: 1.9369 - accuracy: 0.5405 - val_loss: 1.3154 - val_accuracy: 0.6264\n",
            "Epoch 2/10\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2599 - accuracy: 0.6338 - val_loss: 1.1097 - val_accuracy: 0.6717\n",
            "Epoch 3/10\n",
            "108/108 [==============================] - 5s 49ms/step - loss: 1.1174 - accuracy: 0.6609 - val_loss: 1.0067 - val_accuracy: 0.6873\n",
            "Epoch 4/10\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0312 - accuracy: 0.6768 - val_loss: 0.9469 - val_accuracy: 0.6972\n",
            "Epoch 5/10\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9871 - accuracy: 0.6839 - val_loss: 0.9132 - val_accuracy: 0.6961\n",
            "Epoch 6/10\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9271 - accuracy: 0.6988 - val_loss: 0.8383 - val_accuracy: 0.7232\n",
            "Epoch 7/10\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9046 - accuracy: 0.7024 - val_loss: 0.8333 - val_accuracy: 0.7134\n",
            "Epoch 8/10\n",
            "108/108 [==============================] - 6s 53ms/step - loss: 0.8652 - accuracy: 0.7123 - val_loss: 0.8089 - val_accuracy: 0.7250\n",
            "Epoch 9/10\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.8631 - accuracy: 0.7110 - val_loss: 0.7675 - val_accuracy: 0.7428\n",
            "Epoch 10/10\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.8088 - accuracy: 0.7305 - val_loss: 0.8177 - val_accuracy: 0.7076\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f639f530590>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuxfv98C86uw",
        "outputId": "b9df10fa-be5d-45e1-d0b5-64eb329e367d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new jersey est parfois chaud en mois de il et il est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(data_fr[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(data_eng[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66kzIYob-T_y",
        "outputId": "18940747-222e-496e-ec47-4605f11e6e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            "new jersey est parfois chaud en mois de il et il est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "['new jersey est parfois calme pendant l automne  et il est neigeux en avril ']\n",
            "\n",
            "Original text:\n",
            "['new jersey is sometimes quiet during autumn  and it is snowy in april ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Embedding (IMPLEMENTATION)"
      ],
      "metadata": {
        "id": "BJlGr11nChhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_model(input_shape,english_vocab_size,max_french_sequence_length,french_vocab_size) :\n",
        "\n",
        "  # Hyperparameter\n",
        "  learning_rate = .005\n",
        "  # Building model\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(Embedding(english_vocab_size,300 ,input_length= max_french_sequence_length))\n",
        "  model.add(GRU(256,return_sequences = True))\n",
        "  model.add(TimeDistributed(Dense(1024,activation = \"relu\")))\n",
        "  model.add(keras.layers.Dropout(.5))\n",
        "  model.add(TimeDistributed(Dense(french_vocab_size , activation = \"softmax\")))\n",
        "  model.compile(loss = sparse_categorical_crossentropy , metrics = [\"accuracy\"] , optimizer = keras.optimizers.Adam(learning_rate))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "eTsAz3_NB70C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x  = pad(preproc_english_sentences , max_french_sequence_length)\n",
        "tmp_x  = tmp_x .reshape((-1,preproc_french_sentences.shape[-2]))\n",
        "\n",
        "embed_rnn_model = embed_model(tmp_x,english_vocab_size,max_french_sequence_length,french_vocab_size)"
      ],
      "metadata": {
        "id": "J1c4-mHEGwT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_rnn_model.fit(tmp_x,preproc_french_sentences , epochs = 30 , batch_size = 512 , validation_split= .2 )\n",
        "embed_rnn_model.save(\"embed_rnn_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFs6zl6QHcVv",
        "outputId": "a47b0f47-2cea-4a4a-ea30-d91c57bc305a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "216/216 [==============================] - 9s 34ms/step - loss: 0.9852 - accuracy: 0.7506 - val_loss: 0.3857 - val_accuracy: 0.8725\n",
            "Epoch 2/30\n",
            "216/216 [==============================] - 7s 32ms/step - loss: 0.3564 - accuracy: 0.8828 - val_loss: 0.2844 - val_accuracy: 0.9045\n",
            "Epoch 3/30\n",
            "216/216 [==============================] - 7s 32ms/step - loss: 0.2905 - accuracy: 0.9034 - val_loss: 0.2596 - val_accuracy: 0.9122\n",
            "Epoch 4/30\n",
            "216/216 [==============================] - 7s 32ms/step - loss: 0.2645 - accuracy: 0.9108 - val_loss: 0.2379 - val_accuracy: 0.9185\n",
            "Epoch 5/30\n",
            "216/216 [==============================] - 7s 32ms/step - loss: 0.2481 - accuracy: 0.9154 - val_loss: 0.2360 - val_accuracy: 0.9187\n",
            "Epoch 6/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2434 - accuracy: 0.9166 - val_loss: 0.2318 - val_accuracy: 0.9201\n",
            "Epoch 7/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2376 - accuracy: 0.9184 - val_loss: 0.2315 - val_accuracy: 0.9208\n",
            "Epoch 8/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2305 - accuracy: 0.9203 - val_loss: 0.2238 - val_accuracy: 0.9229\n",
            "Epoch 9/30\n",
            "216/216 [==============================] - 7s 34ms/step - loss: 0.2263 - accuracy: 0.9211 - val_loss: 0.2235 - val_accuracy: 0.9232\n",
            "Epoch 10/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2348 - accuracy: 0.9193 - val_loss: 0.2234 - val_accuracy: 0.9235\n",
            "Epoch 11/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2221 - accuracy: 0.9224 - val_loss: 0.2191 - val_accuracy: 0.9242\n",
            "Epoch 12/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2243 - accuracy: 0.9218 - val_loss: 0.2270 - val_accuracy: 0.9222\n",
            "Epoch 13/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2320 - accuracy: 0.9200 - val_loss: 0.2251 - val_accuracy: 0.9234\n",
            "Epoch 14/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2250 - accuracy: 0.9220 - val_loss: 0.2306 - val_accuracy: 0.9228\n",
            "Epoch 15/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2274 - accuracy: 0.9212 - val_loss: 0.2345 - val_accuracy: 0.9213\n",
            "Epoch 16/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2313 - accuracy: 0.9200 - val_loss: 0.2235 - val_accuracy: 0.9239\n",
            "Epoch 17/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2199 - accuracy: 0.9229 - val_loss: 0.2249 - val_accuracy: 0.9244\n",
            "Epoch 18/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2312 - accuracy: 0.9204 - val_loss: 0.2410 - val_accuracy: 0.9196\n",
            "Epoch 19/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2360 - accuracy: 0.9190 - val_loss: 0.2238 - val_accuracy: 0.9237\n",
            "Epoch 20/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2205 - accuracy: 0.9228 - val_loss: 0.2235 - val_accuracy: 0.9238\n",
            "Epoch 21/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2284 - accuracy: 0.9210 - val_loss: 0.2351 - val_accuracy: 0.9218\n",
            "Epoch 22/30\n",
            "216/216 [==============================] - 7s 34ms/step - loss: 0.2271 - accuracy: 0.9213 - val_loss: 0.2269 - val_accuracy: 0.9238\n",
            "Epoch 23/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2225 - accuracy: 0.9223 - val_loss: 0.2274 - val_accuracy: 0.9243\n",
            "Epoch 24/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2252 - accuracy: 0.9218 - val_loss: 0.2336 - val_accuracy: 0.9227\n",
            "Epoch 25/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2390 - accuracy: 0.9184 - val_loss: 0.2363 - val_accuracy: 0.9212\n",
            "Epoch 26/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2312 - accuracy: 0.9203 - val_loss: 0.2247 - val_accuracy: 0.9241\n",
            "Epoch 27/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2235 - accuracy: 0.9222 - val_loss: 0.2259 - val_accuracy: 0.9238\n",
            "Epoch 28/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2202 - accuracy: 0.9228 - val_loss: 0.2303 - val_accuracy: 0.9236\n",
            "Epoch 29/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2437 - accuracy: 0.9172 - val_loss: 0.2383 - val_accuracy: 0.9210\n",
            "Epoch 30/30\n",
            "216/216 [==============================] - 7s 33ms/step - loss: 0.2353 - accuracy: 0.9192 - val_loss: 0.2272 - val_accuracy: 0.9236\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63a1724bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0],french_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tItm9Ab6JSDj",
        "outputId": "9936c24c-4972-42b8-b9e7-bd5c441a9239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new jersey est parfois calme en l automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(data_fr[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(data_eng[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfCKb_R7Kws2",
        "outputId": "3e2cdf4c-5356-43e4-b4c5-299529301cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            "new jersey est parfois calme en l automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "['new jersey est parfois calme pendant l automne  et il est neigeux en avril ']\n",
            "\n",
            "Original text:\n",
            "['new jersey is sometimes quiet during autumn  and it is snowy in april ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Bidirectional RNNs"
      ],
      "metadata": {
        "id": "ctviSpOiLB_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bd_model(input_shape, french_vocab_size):\n",
        "\n",
        "  # HyperParameter \n",
        "  learning_rate = .003\n",
        "\n",
        "  # Build the layers \n",
        "  model = keras.models.Sequential()\n",
        "  model.add(Bidirectional(GRU(256,return_sequences=True),input_shape=input_shape[1:]))\n",
        "  model.add(TimeDistributed(Dense(1024,activation = \"relu\")))\n",
        "  model.add(keras.layers.Dropout(.5))\n",
        "  model.add(TimeDistributed(Dense(french_vocab_size , activation = \"softmax\")))\n",
        "  model.compile(loss = sparse_categorical_crossentropy , metrics = [\"accuracy\"] , optimizer = keras.optimizers.Adam(learning_rate))\n",
        "  return model\n",
        "\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences , max_french_sequence_length )\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2],1))\n",
        "\n",
        "\n",
        "bidirectional_model = bd_model(tmp_x.shape, french_vocab_size)"
      ],
      "metadata": {
        "id": "pKxUYd-FK2Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bidirectional_model.fit(tmp_x, preproc_french_sentences, batch_size=512, epochs=30, validation_split=0.2)\n",
        "bidirectional_model.save(\"bidirectional_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgD6oMc5M5T5",
        "outputId": "8fed2b92-ef21-4572-8327-09ba88bf5e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "216/216 [==============================] - 13s 45ms/step - loss: 1.5286 - accuracy: 0.6028 - val_loss: 1.0951 - val_accuracy: 0.6693\n",
            "Epoch 2/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 1.0549 - accuracy: 0.6734 - val_loss: 0.9478 - val_accuracy: 0.6907\n",
            "Epoch 3/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.9311 - accuracy: 0.6955 - val_loss: 0.8330 - val_accuracy: 0.7173\n",
            "Epoch 4/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.8552 - accuracy: 0.7104 - val_loss: 0.7778 - val_accuracy: 0.7258\n",
            "Epoch 5/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.8087 - accuracy: 0.7193 - val_loss: 0.7137 - val_accuracy: 0.7432\n",
            "Epoch 6/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.7785 - accuracy: 0.7233 - val_loss: 0.7201 - val_accuracy: 0.7343\n",
            "Epoch 7/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.7437 - accuracy: 0.7327 - val_loss: 0.6720 - val_accuracy: 0.7566\n",
            "Epoch 8/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.7063 - accuracy: 0.7461 - val_loss: 0.6169 - val_accuracy: 0.7787\n",
            "Epoch 9/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.7041 - accuracy: 0.7489 - val_loss: 0.6615 - val_accuracy: 0.7533\n",
            "Epoch 10/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.6863 - accuracy: 0.7510 - val_loss: 0.5973 - val_accuracy: 0.7784\n",
            "Epoch 11/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.6648 - accuracy: 0.7585 - val_loss: 0.6471 - val_accuracy: 0.7543\n",
            "Epoch 12/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.6714 - accuracy: 0.7457 - val_loss: 0.5925 - val_accuracy: 0.7676\n",
            "Epoch 13/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.6450 - accuracy: 0.7550 - val_loss: 0.5659 - val_accuracy: 0.7860\n",
            "Epoch 14/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.6145 - accuracy: 0.7722 - val_loss: 0.5461 - val_accuracy: 0.7932\n",
            "Epoch 15/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.5832 - accuracy: 0.7868 - val_loss: 0.5197 - val_accuracy: 0.8082\n",
            "Epoch 16/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.5615 - accuracy: 0.7966 - val_loss: 0.5459 - val_accuracy: 0.7948\n",
            "Epoch 17/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.5541 - accuracy: 0.8009 - val_loss: 0.4602 - val_accuracy: 0.8332\n",
            "Epoch 18/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.5530 - accuracy: 0.8009 - val_loss: 0.5474 - val_accuracy: 0.8004\n",
            "Epoch 19/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.5096 - accuracy: 0.8179 - val_loss: 0.4152 - val_accuracy: 0.8550\n",
            "Epoch 20/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.5345 - accuracy: 0.8091 - val_loss: 0.4422 - val_accuracy: 0.8415\n",
            "Epoch 21/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.4974 - accuracy: 0.8219 - val_loss: 0.4028 - val_accuracy: 0.8569\n",
            "Epoch 22/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.5038 - accuracy: 0.8191 - val_loss: 0.4616 - val_accuracy: 0.8329\n",
            "Epoch 23/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.4724 - accuracy: 0.8294 - val_loss: 0.3978 - val_accuracy: 0.8578\n",
            "Epoch 24/30\n",
            "216/216 [==============================] - 9s 42ms/step - loss: 0.4795 - accuracy: 0.8270 - val_loss: 0.4186 - val_accuracy: 0.8493\n",
            "Epoch 25/30\n",
            "216/216 [==============================] - 9s 43ms/step - loss: 0.4815 - accuracy: 0.8273 - val_loss: 0.3707 - val_accuracy: 0.8691\n",
            "Epoch 26/30\n",
            "216/216 [==============================] - 9s 43ms/step - loss: 0.4714 - accuracy: 0.8301 - val_loss: 0.4009 - val_accuracy: 0.8567\n",
            "Epoch 27/30\n",
            "216/216 [==============================] - 9s 43ms/step - loss: 0.4852 - accuracy: 0.8241 - val_loss: 0.4254 - val_accuracy: 0.8487\n",
            "Epoch 28/30\n",
            "216/216 [==============================] - 9s 43ms/step - loss: 0.4704 - accuracy: 0.8303 - val_loss: 0.4268 - val_accuracy: 0.8432\n",
            "Epoch 29/30\n",
            "216/216 [==============================] - 9s 43ms/step - loss: 0.4508 - accuracy: 0.8379 - val_loss: 0.4127 - val_accuracy: 0.8520\n",
            "Epoch 30/30\n",
            "216/216 [==============================] - 9s 43ms/step - loss: 0.4246 - accuracy: 0.8477 - val_loss: 0.3536 - val_accuracy: 0.8745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63a0a830d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_to_text(bidirectional_model.predict(tmp_x[:1])[0],french_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ts_7cMufL9xW",
        "outputId": "c6ffa0d3-f13a-44d8-9ffb-5c5b2ccac195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new jersey est parfois calme pendant lautomne de l automne il il en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(bidirectional_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(data_fr[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(data_eng[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woganQPZSNuU",
        "outputId": "6ea0c96f-9c26-4de1-dc25-f65428572e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            "new jersey est parfois calme pendant lautomne de l automne il il en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "['new jersey est parfois calme pendant l automne  et il est neigeux en avril ']\n",
            "\n",
            "Original text:\n",
            "['new jersey is sometimes quiet during autumn  and it is snowy in april ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Encoder-Decoder"
      ],
      "metadata": {
        "id": "Cn-nRL8AqQXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encdec_model(input_shape, french_vocab_size , output_sequence_length):\n",
        "\n",
        "  # HyperParameter \n",
        "  learning_rate = .003\n",
        "\n",
        "  # Build the layers \n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "  # Encoder\n",
        "  model.add(GRU(256, go_backwards=True,input_shape=input_shape[1:]))\n",
        "  model.add(keras.layers.RepeatVector(output_sequence_length))\n",
        "  # Decoder\n",
        "  model.add(GRU(256 , return_sequences = True ))\n",
        "  model.add(TimeDistributed(Dense(1024,activation = \"relu\")))\n",
        "  model.add(keras.layers.Dropout(.5))\n",
        "  model.add(TimeDistributed(Dense(french_vocab_size , activation = \"softmax\")))\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss = sparse_categorical_crossentropy , metrics = [\"accuracy\"] , optimizer = keras.optimizers.Adam(learning_rate))\n",
        "  return model\n",
        "\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences , max_french_sequence_length )\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2],1))\n",
        "\n",
        "\n",
        "encdec_rnn_model  = encdec_model(tmp_x.shape, french_vocab_size , max_french_sequence_length )\n",
        "encdec_rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEB5_v66Uf4x",
        "outputId": "9c0249ac-6752-4fd1-aa57-0e5bdb58f6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 256)               198912    \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 21, 256)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 21, 256)           394752    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 21, 1024)         263168    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 21, 344)          352600    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,209,432\n",
            "Trainable params: 1,209,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encdec_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=30, validation_split=0.2)\n",
        "encdec_rnn_model.save(\"encdec_rnn_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgq-AOEutnRX",
        "outputId": "901b848b-67f5-47d7-e20e-70fd70138b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "108/108 [==============================] - 13s 77ms/step - loss: 2.3048 - accuracy: 0.4908 - val_loss: nan - val_accuracy: 0.5982\n",
            "Epoch 2/30\n",
            "108/108 [==============================] - 7s 69ms/step - loss: 1.4805 - accuracy: 0.5999 - val_loss: nan - val_accuracy: 0.6373\n",
            "Epoch 3/30\n",
            "108/108 [==============================] - 7s 69ms/step - loss: 1.3203 - accuracy: 0.6304 - val_loss: nan - val_accuracy: 0.6535\n",
            "Epoch 4/30\n",
            "108/108 [==============================] - 7s 69ms/step - loss: 1.2267 - accuracy: 0.6477 - val_loss: nan - val_accuracy: 0.6708\n",
            "Epoch 5/30\n",
            "108/108 [==============================] - 8s 70ms/step - loss: 1.1843 - accuracy: 0.6510 - val_loss: nan - val_accuracy: 0.6698\n",
            "Epoch 6/30\n",
            "108/108 [==============================] - 8s 70ms/step - loss: 1.1046 - accuracy: 0.6694 - val_loss: nan - val_accuracy: 0.6432\n",
            "Epoch 7/30\n",
            "108/108 [==============================] - 8s 71ms/step - loss: 1.0744 - accuracy: 0.6753 - val_loss: nan - val_accuracy: 0.7068\n",
            "Epoch 8/30\n",
            "108/108 [==============================] - 8s 71ms/step - loss: 0.9965 - accuracy: 0.6967 - val_loss: nan - val_accuracy: 0.7238\n",
            "Epoch 9/30\n",
            "108/108 [==============================] - 8s 71ms/step - loss: 0.9096 - accuracy: 0.7167 - val_loss: nan - val_accuracy: 0.7318\n",
            "Epoch 10/30\n",
            "108/108 [==============================] - 8s 71ms/step - loss: 0.9203 - accuracy: 0.7118 - val_loss: nan - val_accuracy: 0.7319\n",
            "Epoch 11/30\n",
            "108/108 [==============================] - 8s 71ms/step - loss: 0.9262 - accuracy: 0.7065 - val_loss: nan - val_accuracy: 0.7145\n",
            "Epoch 12/30\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.8677 - accuracy: 0.7214 - val_loss: nan - val_accuracy: 0.7494\n",
            "Epoch 13/30\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.8074 - accuracy: 0.7363 - val_loss: nan - val_accuracy: 0.7429\n",
            "Epoch 14/30\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.8264 - accuracy: 0.7313 - val_loss: nan - val_accuracy: 0.7563\n",
            "Epoch 15/30\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.7600 - accuracy: 0.7479 - val_loss: nan - val_accuracy: 0.7506\n",
            "Epoch 16/30\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.7565 - accuracy: 0.7491 - val_loss: nan - val_accuracy: 0.7636\n",
            "Epoch 17/30\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.7075 - accuracy: 0.7619 - val_loss: nan - val_accuracy: 0.7518\n",
            "Epoch 18/30\n",
            "108/108 [==============================] - 8s 72ms/step - loss: 0.6896 - accuracy: 0.7653 - val_loss: nan - val_accuracy: 0.7922\n",
            "Epoch 19/30\n",
            "108/108 [==============================] - 8s 73ms/step - loss: 0.6796 - accuracy: 0.7680 - val_loss: nan - val_accuracy: 0.7877\n",
            "Epoch 20/30\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.6761 - accuracy: 0.7670 - val_loss: nan - val_accuracy: 0.7817\n",
            "Epoch 21/30\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.6268 - accuracy: 0.7817 - val_loss: nan - val_accuracy: 0.7429\n",
            "Epoch 22/30\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.6638 - accuracy: 0.7725 - val_loss: nan - val_accuracy: 0.8152\n",
            "Epoch 23/30\n",
            "108/108 [==============================] - 8s 75ms/step - loss: 0.6078 - accuracy: 0.7886 - val_loss: nan - val_accuracy: 0.8137\n",
            "Epoch 24/30\n",
            "108/108 [==============================] - 8s 75ms/step - loss: 0.5717 - accuracy: 0.7992 - val_loss: nan - val_accuracy: 0.8162\n",
            "Epoch 25/30\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5832 - accuracy: 0.7946 - val_loss: nan - val_accuracy: 0.8152\n",
            "Epoch 26/30\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5702 - accuracy: 0.7992 - val_loss: nan - val_accuracy: 0.8054\n",
            "Epoch 27/30\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5380 - accuracy: 0.8080 - val_loss: nan - val_accuracy: 0.8045\n",
            "Epoch 28/30\n",
            "108/108 [==============================] - 8s 74ms/step - loss: 0.5286 - accuracy: 0.8110 - val_loss: nan - val_accuracy: 0.8141\n",
            "Epoch 29/30\n",
            "108/108 [==============================] - 8s 76ms/step - loss: 0.5195 - accuracy: 0.8145 - val_loss: nan - val_accuracy: 0.8338\n",
            "Epoch 30/30\n",
            "108/108 [==============================] - 8s 76ms/step - loss: 0.4831 - accuracy: 0.8249 - val_loss: nan - val_accuracy: 0.8463\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef287b7f50>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_to_text(encdec_rnn_model.predict(tmp_x[:1])[0],french_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gC6s880qxJgq",
        "outputId": "c8e4ab6f-4c87-47a4-b62d-2c137b47139d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new jersey est parfois calme au cours et il est il est avril en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(encdec_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(data_fr[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(data_eng[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhuGrl3Otylg",
        "outputId": "466503fe-defe-49c4-f335-b9776eff3862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            "new jersey est parfois calme au cours et il est il est avril en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "['new jersey est parfois calme pendant l automne  et il est neigeux en avril ']\n",
            "\n",
            "Original text:\n",
            "['new jersey is sometimes quiet during autumn  and it is snowy in april ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5: Custom ( Using all of the above models )"
      ],
      "metadata": {
        "id": "31P_hzZ8xTgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_final(input_shape, english_vocab_size , french_vocab_size , output_sequence_length):\n",
        "\n",
        "  # HyperParameter \n",
        "  learning_rate = .003\n",
        "\n",
        "  # Build the layers \n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "  # Encoder\n",
        "  model.add(keras.layers.Embedding(english_vocab_size , 300 , input_length=input_shape[1] , input_shape = input_shape[1:] ))\n",
        "  model.add(Bidirectional(GRU(256, go_backwards=True)))\n",
        "  model.add(keras.layers.RepeatVector(output_sequence_length))\n",
        "\n",
        "  # Decoder\n",
        "  model.add(Bidirectional(GRU(256 , return_sequences = True )))\n",
        "  model.add(TimeDistributed(Dense(1024,activation = \"relu\")))\n",
        "  model.add(keras.layers.Dropout(.5))\n",
        "  model.add(TimeDistributed(Dense(french_vocab_size , activation = \"softmax\")))\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss = sparse_categorical_crossentropy , metrics = [\"accuracy\"] , optimizer = keras.optimizers.Adam(learning_rate))\n",
        "  return model"
      ],
      "metadata": {
        "id": "a0ONHPwzwlL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x = pad(preproc_english_sentences , max_french_sequence_length )\n",
        "tmp_x = tmp_x.reshape((-1,preproc_french_sentences.shape[1]))\n",
        "\n",
        "final_model = model_final( tmp_x.shape ,english_vocab_size , french_vocab_size , max_french_sequence_length )"
      ],
      "metadata": {
        "id": "CvU2iQNZzSPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(tmp_x , preproc_french_sentences , validation_split= .2 , epochs = 20 , batch_size = 512 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_fs-NL_2ppl",
        "outputId": "bd6f802a-3fe3-4255-c016-f6ef90b82ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "216/216 [==============================] - 23s 81ms/step - loss: 1.6237 - accuracy: 0.6066 - val_loss: nan - val_accuracy: 0.7101\n",
            "Epoch 2/20\n",
            "216/216 [==============================] - 17s 77ms/step - loss: 0.8006 - accuracy: 0.7632 - val_loss: nan - val_accuracy: 0.8265\n",
            "Epoch 3/20\n",
            "216/216 [==============================] - 17s 78ms/step - loss: 0.4779 - accuracy: 0.8525 - val_loss: nan - val_accuracy: 0.9111\n",
            "Epoch 4/20\n",
            "216/216 [==============================] - 17s 78ms/step - loss: 0.2860 - accuracy: 0.9138 - val_loss: nan - val_accuracy: 0.9454\n",
            "Epoch 5/20\n",
            "216/216 [==============================] - 17s 78ms/step - loss: 0.2016 - accuracy: 0.9398 - val_loss: nan - val_accuracy: 0.9573\n",
            "Epoch 6/20\n",
            "216/216 [==============================] - 17s 79ms/step - loss: 0.1523 - accuracy: 0.9541 - val_loss: nan - val_accuracy: 0.9637\n",
            "Epoch 7/20\n",
            "216/216 [==============================] - 17s 79ms/step - loss: 0.1271 - accuracy: 0.9614 - val_loss: nan - val_accuracy: 0.9698\n",
            "Epoch 8/20\n",
            "216/216 [==============================] - 17s 80ms/step - loss: 0.1089 - accuracy: 0.9665 - val_loss: nan - val_accuracy: 0.9694\n",
            "Epoch 9/20\n",
            "216/216 [==============================] - 17s 80ms/step - loss: 0.1048 - accuracy: 0.9678 - val_loss: nan - val_accuracy: 0.9722\n",
            "Epoch 10/20\n",
            "216/216 [==============================] - 17s 80ms/step - loss: 0.0881 - accuracy: 0.9727 - val_loss: nan - val_accuracy: 0.9755\n",
            "Epoch 11/20\n",
            "216/216 [==============================] - 17s 80ms/step - loss: 0.0871 - accuracy: 0.9734 - val_loss: nan - val_accuracy: 0.9780\n",
            "Epoch 12/20\n",
            "216/216 [==============================] - 17s 81ms/step - loss: 0.0915 - accuracy: 0.9720 - val_loss: nan - val_accuracy: 0.9729\n",
            "Epoch 13/20\n",
            "216/216 [==============================] - 18s 83ms/step - loss: 0.0885 - accuracy: 0.9728 - val_loss: nan - val_accuracy: 0.9774\n",
            "Epoch 14/20\n",
            "216/216 [==============================] - 18s 83ms/step - loss: 0.0714 - accuracy: 0.9779 - val_loss: nan - val_accuracy: 0.9752\n",
            "Epoch 15/20\n",
            "216/216 [==============================] - 18s 81ms/step - loss: 0.0648 - accuracy: 0.9798 - val_loss: nan - val_accuracy: 0.9801\n",
            "Epoch 16/20\n",
            "216/216 [==============================] - 18s 82ms/step - loss: 0.0606 - accuracy: 0.9811 - val_loss: nan - val_accuracy: 0.9775\n",
            "Epoch 17/20\n",
            "216/216 [==============================] - 18s 83ms/step - loss: 0.0621 - accuracy: 0.9807 - val_loss: nan - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "216/216 [==============================] - 18s 83ms/step - loss: 0.0823 - accuracy: 0.9749 - val_loss: nan - val_accuracy: 0.9809\n",
            "Epoch 19/20\n",
            "216/216 [==============================] - 18s 83ms/step - loss: 0.0618 - accuracy: 0.9810 - val_loss: nan - val_accuracy: 0.9783\n",
            "Epoch 20/20\n",
            "216/216 [==============================] - 18s 83ms/step - loss: 0.0601 - accuracy: 0.9814 - val_loss: nan - val_accuracy: 0.9793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef289d9510>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "final_model.save(\"final_model\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svp8A0RCAbhB",
        "outputId": "5dcfd401-0acc-423d-a916-96cc287b4195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_6_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fef297bec10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fef295f3cd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fef294b9ad0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fef2916cf10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_to_text(final_model.predict(tmp_x[:1])[0],french_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FcpVfwfb4VHF",
        "outputId": "531bc881-b428-41bb-8542-53004f3985a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new jersey est parfois calme pendant l automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(final_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(data_fr[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(data_eng[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoqrjsGL5xbF",
        "outputId": "54d95d7b-6090-4c36-c473-7ac350578c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            "new jersey est parfois calme pendant l automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "['new jersey est parfois calme pendant l automne  et il est neigeux en avril ']\n",
            "\n",
            "Original text:\n",
            "['new jersey is sometimes quiet during autumn  and it is snowy in april ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions with the final model"
      ],
      "metadata": {
        "id": "Kqr5vyvNAKUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text) :\n",
        "  sequence = [english_tokenizer.word_index[word] for word in text.split()]\n",
        "  padded_sequence =  pad_sequences([sequence] , maxlen = 21 , padding = \"post\")\n",
        "  print(logits_to_text(encdec_rnn_model.predict(padded_sequence)[0], french_tokenizer))"
      ],
      "metadata": {
        "id": "xjSkPb6i9mZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"he saw a old yellow truck\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psqegGqx9yqQ",
        "outputId": "9c3fa802-98cd-41ef-ba78-9a8d54168497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "il a pas un camion voiture <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}